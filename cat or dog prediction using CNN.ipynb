{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqHjzrgxg+3wbSUk4Uudwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jishnuks17/Machine-Learning-Algorithms/blob/main/cat%20or%20dog%20prediction%20using%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KixnFgboF1gf",
        "outputId": "8142314f-a0d5-4963-9a5a-4ba9afe7ee7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GV_DeepLearning'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 953\u001b[K\n",
            "Receiving objects: 100% (956/956), 18.10 MiB | 38.52 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "Hp_a5IZ3MU0u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Omn3IfTNM7HT",
        "outputId": "0001bd86-55af-4603-c06c-8727c8962481"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TrainingSet',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,cnn\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI6Hg7vtNCXg",
        "outputId": "2b82b143-a644-4964-8c82-0e5ab9f01dd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 692 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TestSet',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilTnZ6kTP7W-",
        "outputId": "5cacc5c3-c591-4cfa-c0fc-3df2f7434c1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "TMtwopB7QV7V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "619-R9FhQn5a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "bhFqPj46RPBw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "gjHc_77hRYYJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "-CYtR1k1RZvo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "G_YzXMusRdVy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "FYnUlVaWRnts"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "vxF59wJfR5dl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFN8RxelR_hr",
        "outputId": "b629b6d0-e71d-40b1-d2b9-a8980c89ba85"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.6897 - accuracy: 0.5708 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.6891 - accuracy: 0.5708 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 8s 365ms/step - loss: 0.6885 - accuracy: 0.5708 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 7s 332ms/step - loss: 0.6881 - accuracy: 0.5708 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 6s 276ms/step - loss: 0.6874 - accuracy: 0.5708 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.6871 - accuracy: 0.5708 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 6s 289ms/step - loss: 0.6867 - accuracy: 0.5708 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 6s 279ms/step - loss: 0.6863 - accuracy: 0.5708 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.6860 - accuracy: 0.5708 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 6s 248ms/step - loss: 0.6857 - accuracy: 0.5708 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.6855 - accuracy: 0.5708 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 6s 269ms/step - loss: 0.6852 - accuracy: 0.5708 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 6s 286ms/step - loss: 0.6850 - accuracy: 0.5708 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6848 - accuracy: 0.5708 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.6846 - accuracy: 0.5708 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.6845 - accuracy: 0.5708 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 6s 249ms/step - loss: 0.6843 - accuracy: 0.5708 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 6s 249ms/step - loss: 0.6842 - accuracy: 0.5708 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 9s 394ms/step - loss: 0.6841 - accuracy: 0.5708 - val_loss: 0.6981 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 7s 294ms/step - loss: 0.6839 - accuracy: 0.5708 - val_loss: 0.6983 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b6ef77910>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/GV_DeepLearning/Dataset/SingleImage/cat_or_dog_2.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "bfaVkqFPSl2V"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S0peG-DTJJh",
        "outputId": "664b1190-aac1-44b9-f197-bf50c4bcf1bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    }
  ]
}